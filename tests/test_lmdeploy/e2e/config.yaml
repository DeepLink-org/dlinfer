tp_config:
    qwen_model/Qwen3-30B-A3B: 2
    InternVL2-26B: 2

graph_config:
    internlm3-8b-instruct: True
    Meta-Llama-3-8B-Instruct: True
    Qwen3-30B-A3B: True
    Qwen2.5-7B-Instruct: True
    Qwen2.5-VL-7B-Instruct: True
    InternVL2-2B: True
    InternVL2-26B: True

pytorch_chat_model:
    - internlm_model/internlm3-8b-instruct
    - llama_model/Meta-Llama-3.1-8B-Instruct
    - qwen_model/Qwen3-30B-A3B
    - qwen_model/Qwen2.5-7B-Instruct

pytorch_vl_model:
    - internvl_model/InternVL2-26B
    - internvl_model/InternVL2-2B
    - qwen_model/Qwen2-VL-7B-Instruct
